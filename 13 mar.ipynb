{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5afd1fee-3eab-40d3-bc4e-062ed9756028",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Ans:\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means across multiple groups or treatments. To ensure the validity of ANOVA results, certain assumptions need to be met. Violations of these assumptions can impact the validity of the results\n",
    "Independence: The observations within each group or treatment are assumed to be independent of each other. Violations of independence occur when there is a dependence or correlation between the observations within groups. For example, if the same individuals are measured in multiple groups, violating the assumption of independence.\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution. Violations of normality occur when the data deviates significantly from a normal distribution. This can happen if the data is heavily skewed or has outliers. For example, if the data is highly skewed or has a heavy-tailed distribution.\n",
    "\n",
    "Homogeneity of Variance: The variances of the groups being compared should be equal. Violations of homogeneity of variance occur when the variability differs significantly across groups. This is known as heteroscedasticity. For example, if the variability of the data is much larger in one group compared to others.\n",
    "\n",
    "Homogeneity of Covariance: This assumption is specific to repeated measures or within-subjects ANOVA. It assumes that the covariances between different measurements within the same subject are equal across groups. Violations occur when the covariances differ significantly across groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df7d04-0899-4631-a3b8-efc0b8b51b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ca29342-0b6f-4076-a058-5554559cc46b",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Ans:\n",
    "The three types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more independent groups or treatments. It is called \"One-Way\" because it involves only one factor or independent variable. This type of ANOVA is suitable when you want to determine if there are significant differences among the means of multiple groups. For example, you might use One-Way ANOVA to compare the effectiveness of different treatments on patient outcomes or to compare the mean scores of students across multiple schools.\n",
    "\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when there are two independent variables or factors. It allows you to simultaneously analyze the effects of two factors and their interactions on the dependent variable. The factors can be either independent or related, and each factor can have multiple levels. Two-Way ANOVA is useful when you want to examine how two factors interact and influence the dependent variable. For example, you might use Two-Way ANOVA to analyze the effects of both gender and age group on test scores or to study the interaction between different factors affecting crop yields.\n",
    "\n",
    "Repeated Measures ANOVA: Repeated Measures ANOVA, also known as within-subjects ANOVA or paired ANOVA, is used when the same subjects are measured under multiple conditions or time points. It is suitable for studying the effects of a single factor with repeated measurements or when comparing the means of different conditions within the same group of participants. Repeated Measures ANOVA is useful when you want to analyze the changes over time or conditions within the same individuals. For example, you might use Repeated Measures ANOVA to analyze the effects of different doses of a medication on blood pressure levels or to compare the performance of individuals before and after a training program.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "581022bb-ab8d-4740-926c-4e4450489677",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Ans:\n",
    "Total Sum of Squares (SST): This represents the total variation in the data and is calculated as the sum of squared differences between each observation and the overall mean.\n",
    "\n",
    "Between-Group Sum of Squares (SSB): This component measures the variation between the group means and the overall mean. It is calculated as the sum of squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "\n",
    "Within-Group Sum of Squares (SSW): This component reflects the variation within each group. It is calculated as the sum of squared differences between each observation and its group mean, summed across all groups.\n",
    "\n",
    "The partitioning of variance is important because it allows us to assess the contributions of different factors to the total variation observed in the data. By decomposing the total variation into between-group and within-group components, ANOVA helps us determine whether there are significant differences among the groups being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a470723-983b-4c03-88be-0c4d079e8863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "cdc5c37c-466f-4a87-9616-f7c8e1356a3e",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da345fae-32b4-4eb3-a2fb-a194e55f4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 45.33333333333331\n",
      "SSE: 8.333333333333309\n",
      "SSR: 37.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = {'Group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'Values': [ 10, 13, 16, 12, 15, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#fit one-way Anova model\n",
    "model = ols('Values~Group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "#Extract sums of squares from the ANOVA table\n",
    "SST = anova_table['sum_sq'].sum() # Total sum of squares\n",
    "SSE = anova_table['sum_sq'][0] #Explained sum of squares (b/w-group sum of squares)\n",
    "SSR = anova_table['sum_sq'][1]# Residual sum of squares (within-group sum of squares)\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\",SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff2172-d444-4d34-85c5-71cf5ba5a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b3246c61-0f67-488d-9895-c65202a4ad45",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8569edee-3c65-4910-be8b-4fda4d1b469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect 1: 28.00000000000002\n",
      "Main Effect 2: 20.166666666666647\n",
      "Interaction Effect : 5.333333333333318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/stats/anova.py:138: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  (model.ssr / model.df_resid))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = {'Group1' : ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'Group2' : ['X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "        'Values' : [9, 14, 12, 13, 5, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#fit two-way anova model\n",
    "model = ols('Values ~ Group1 + Group2 + Group1:Group2', data = df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effect from the ANOVA table\n",
    "main_effect1 = anova_table['sum_sq']['Group1']\n",
    "main_effect2 = anova_table['sum_sq']['Group2']\n",
    "interaction_effect = anova_table['sum_sq']['Group1:Group2']\n",
    "\n",
    "print(\"Main Effect 1:\", main_effect1)\n",
    "print(\"Main Effect 2:\", main_effect2)\n",
    "print(\"Interaction Effect :\", interaction_effect)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbceef49-7993-4357-a806-0b8290390ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d58c3501-affb-4e86-a22e-46f9d4548725",
   "metadata": {},
   "source": [
    " Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7931d57-56c5-497e-9a23-2095bebe467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 4.333333333333333\n",
      "p-value: 0.1303952278723997\n",
      "There are no significant differences between the groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = {'Group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'Values': [10, 12, 8, 9, 11, 13]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit one-way ANOVA model\n",
    "model = ols('Values ~ Group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract F-statistic and p-value from the ANOVA table\n",
    "F_statistic = anova_table['F'][0]\n",
    "p_value = anova_table['PR(>F)'][0]\n",
    "\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check significance level at 0.05\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences between the groups.\")\n",
    "else:\n",
    "    print(\"There are no significant differences between the groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93866b3f-9fa2-4297-9484-d1d71696ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9782bd8a-9888-4148-a3c7-9acfcf375d29",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "Ans:\n",
    "\n",
    "Listwise deletion: In this method, any subject with missing data on any of the variables is completely excluded from the analysis. This approach uses only the complete cases, discarding all cases with any missing values. While it is straightforward to implement, listwise deletion reduces the sample size, potentially resulting in decreased statistical power and biased estimates if the missing data mechanism is not completely random.\n",
    "\n",
    "Pairwise deletion: This method includes all available cases for each specific comparison within the ANOVA, even if there are missing values in other comparisons. It maximizes the sample size and retains more data compared to listwise deletion. However, it can lead to biased estimates if the missing data are not missing completely at random (MCAR) and can yield different results depending on the specific comparisons made.\n",
    "\n",
    "Mean imputation: In mean imputation, missing values are replaced with the mean value of the observed data for that variable. It is a simple and commonly used method but can underestimate the standard errors, inflate statistical significance, and distort the covariance structure between variables, potentially leading to biased results.\n",
    "\n",
    "Multiple imputation: Multiple imputation generates multiple plausible imputations for the missing values, accounting for the uncertainty of the missing data. The missing values are imputed based on observed data and the estimated relationships among variables. Multiple analyses are then conducted on each imputed dataset, and the results are pooled to provide valid estimates. Multiple imputation is considered more robust and can provide unbiased estimates if the imputation model is correctly specified. However, it can be computationally intensive and requires careful implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d43ee6-0765-4cdc-b183-82165587f02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3a995143-583c-4e32-89b1-de2944d299a1",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "Ans:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test :. This test is widely used and compares all possible pairwise differences between group means while controlling the family-wise error rate. Tukey's HSD is appropriate when the sample sizes are equal or close to equal and the variances are homogeneous.\n",
    "\n",
    "Bonferroni correction: This method adjusts the significance level for multiple comparisons. The Bonferroni correction divides the desired significance level (e.g., 0.05) by the number of comparisons being made. It is a conservative approach and can be used with any type of post-hoc test to control the family-wise error rate .\n",
    "\n",
    "Scheffé's test: Scheffé's test is more conservative than Tukey's HSD but is suitable for situations where the assumption of homogeneous variances is violated or the sample sizes are unequal. It allows for all possible pairwise comparisons and controls the family-wise error rate .\n",
    "\n",
    "Dunnett's test ,: Dunnett's test compares each group mean against a control or reference group mean . It is useful when there is a specific control group to which all other groups are compared . Dunnett's test helps identify significant differences between each treatment group and the control group while controlling the overall Type I error rate .\n",
    "\n",
    "Fisher's Least Significant Difference (LSD) test: Fisher's LSD test compares each pair of group means individuallt. It does not control the family-wise error rate , so it is more suitable for exploratory analyses or situations where the number of comparisons is small .\n",
    "\n",
    "Games-Howell test : The Games-Howell test is a robust alternative to Tukey's HSD when the assumption of homogeneous variances is violated or the sample sizes are unequal . It uses rank-based transformations and does not assume equal variances across  groups ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e855c-9a20-44d9-ac48-d8e4df11e81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "987c5de2-4b83-4c2b-a3db-20a73405d590",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf002d5-7608-40f2-8eef-bc0295d448bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic : 28.308230737350062\n",
      "p-value: 4.282591817456252e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "diet_A = np.array([2, 3, 4, 3, 5, 4, 3, 2, 1, 2, 3, 4, 3, 4, 2, 3, 4, 5, 3, 4,\n",
    "                   2, 3, 4, 3, 5, 4, 3, 2, 1, 2, 3, 4, 3, 4, 2, 3, 4, 5, 3, 4,\n",
    "                   2, 3, 4, 3, 5, 4, 3, 2, 1, 2])\n",
    "diet_B = np.array([1, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2,\n",
    "                   3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2,\n",
    "                   3, 2, 1, 2, 3, 2, 1, 2, 3])\n",
    "diet_C = np.array([3, 3, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n",
    "                   2, 3, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n",
    "                   2, 3, 2, 3, 2, 1, 2, 3])\n",
    "\n",
    "# prfrom one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic :\", f_statistic)\n",
    "print(\"p-value:\" , p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4997688-63f8-4634-b98e-c7103526e1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "14a30944-0b5a-470e-bfd2-c8055f1f2610",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0f04dc-c052-4cea-9d75-ca4c10f85e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ols\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgram\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNovice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperienced\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m11\u001b[39m]\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime ~ Program + Experience + Program:Experience\u001b[39m\u001b[38;5;124m'\u001b[39m , data \u001b[38;5;241m=\u001b[39m df)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     13\u001b[0m anova_table \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39manova_lm(model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {\n",
    "    'Program': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'B', 'C', 'A', 'A', 'B', 'C', 'C', 'A', 'B', 'B', 'C', 'A', 'B', 'C', 'A', 'A', 'B', 'C', 'C', 'A', 'B', 'C'],\n",
    "    'Experience': ['Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced'],\n",
    "    'Time': [10, 12, 8, 9, 11, 13, 15, 14, 12, 10, 11, 9, 13, 12, 11, 10, 9, 8, 12, 10, 11, 13, 14, 9, 8, 7, 13, 12, 11]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "model = ols('Time ~ Program + Experience + Program:Experience' , data = df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "print(anova_table)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b510f-3250-456d-a0b3-62dd6799b54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "02ac7015-1e14-41f0-b90d-196e74abba57",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60cb580a-a0c3-4d5f-97d8-218944eac076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_statistic :  -2.1892700609774267\n",
      "p_value : 0.03261489978774544\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# traditional teaching method\n",
    "control_group = np.array([78, 85, 72, 90, 82, 88, 76, 80, 85, 79, 84, 77, 81, 87, 83, 79, 86, 75, 80, 88, 84, 76, 79, 83, 85, 82, 81, 87, 80, 84])\n",
    "\n",
    "# new teaching method\n",
    "experimental_group = np.array([82, 88, 85, 91, 87, 84, 76, 79, 83, 79, 85, 80, 87, 90, 83, 78, 81, 85, 89, 86, 83, 80, 84, 88, 81, 86, 89, 82, 85, 90])\n",
    "\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"t_statistic : \" , t_stat)\n",
    "print(\"p_value :\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cae28c-fc2d-43fd-8151-bea953b4de2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b08d984d-56f2-429c-98ef-6b240dd01277",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10307709-aeb8-48e1-8451-3722b468fddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            df       sum_sq    mean_sq         F    PR(>F)\n",
      "Store      2.0    11.666667   5.833333  0.106674  0.898995\n",
      "C(Day)    29.0  2856.666667  98.505747  1.801366  0.028515\n",
      "Residual  58.0  3171.666667  54.683908       NaN       NaN\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1  group2 meandiff p-adj   lower  upper  reject\n",
      "-----------------------------------------------------\n",
      "Store A Store B  -0.1667 0.9967 -5.2916 4.9583  False\n",
      "Store A Store C   0.6667 0.9484 -4.4583 5.7916  False\n",
      "Store B Store C   0.8333 0.9206 -4.2916 5.9583  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Day': list(range(30)),\n",
    "    'Store A': [100, 120, 110, 90, 95, 105, 115, 100, 105, 110, 115, 105, 100, 120, 110, 95, 105, 115, 100, 105, 110, 115, 105, 100, 120, 110, 90, 95, 105, 115],\n",
    "    'Store B': [90, 95, 105, 115, 105, 100, 120, 110, 115, 105, 100, 120, 110, 95, 105, 115, 100, 105, 110, 115, 105, 100, 90, 95, 105, 115, 105, 100, 120, 110],\n",
    "    'Store C': [100, 105, 110, 115, 105, 100, 120, 110, 115, 105, 100, 120, 110, 95, 105, 115, 100, 105, 110, 115, 105, 100, 90, 95, 105, 115, 105, 100, 120, 110]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reshape the data into long format\n",
    "df_long = pd.melt(df, id_vars='Day', var_name='Store', value_name='Sales')\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ Store + C(Day)', data=df_long).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Perform the Tukey HSD test\n",
    "tukey_results = mc.MultiComparison(df_long['Sales'], df_long['Store']).tukeyhsd()\n",
    "\n",
    "# Print the pairwise group comparisons and p-values\n",
    "print(tukey_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade1ffc-32d9-4e7e-85c4-1867a3cf82fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
